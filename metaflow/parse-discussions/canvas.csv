web-scraper-order,web-scraper-start-url,discussion_subentries
"1581151650-90","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","MusicFX uses the preferences of music from the gym members. However, people who are exercising tend to listen to a different kind of music than when they are not exercising.
Hence, does the preference system MusicFX created perform on an optimal level?
 
  
    Edited by Kaspar Raijmann on 5 Feb at 11:34"
"1581151650-75","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","MusicFX gives each member a certain degree of decision power to influence the music played in the fitness center. As described in the paper, some members deliberately altered their music preferences on the spot such that it would manipulate the radio station to one of their liking.
Does manipulating the system in this manner harm the music experience of the collective group? And if so, how should a system like MusicFX prevent such behavior?"
"1581151650-60","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","Add you short discussion topics here on the first paper
            
                This topic is closed for comments."
"1581151650-86","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","How to improve performance of MusicFX ?
Would the performance improve making it  context aware (taking into account date and time) and adding the order of sequence? 
  
    Edited by Massimo Manca on 5 Feb at 10:50"
"1581151650-70","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","The authors state that the music choice in the fitness center was already a controversial topic. I do not think the fact that 71% of the users said it improved tells us too much. However, I do like the overall satisfaction rating (0.44 -> 0.64), maybe they could have included some more statistical metrics like this."
"1581151650-79","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","Possible Discussion Topic:
Might a group recommender system similar to the one described in the article facilitate the exclusion of minorities in its proposals and thereby converge to a few mainstream tastes/ ideas stripping the present group from extremes? Could there be a case where it is not desirable to go with the taste of the majority?"
"1581151650-82","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","The current group preference music recommendation system would be subject to the cold start problem (Markus Schedl et al, 2018). Like most recommendation systems, the weakest link in the chain is the initiation aspect where the user is expected to enter his/her preferences. Could asking the user to rate over 90 stations based on the limited exposure to that station in a short window of time would produce half-hearted ratings towards unfamiliar stations and genres? Since the activity of rating 90 stations in a fitness studio seems cumbersome, could  it inspire prejudice against the stations that do not offer the user's favourite  genre of music?
 
  
    Edited by Nikhil Mukkatira on 4 Feb at 23:59"
"1581151650-73","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","The MusicFX paper (1998) mentions a music recommender system in a gym and also a general environment recommender system for/using inhabitants of any environment. The recommender in the paper uses part diversification; it chooses 3 genres that were most preferred and plays these for a limited amount of time. A recommender could also use majority ruling and just play what is liked most (m=1) or fully diversify based on anything that is liked. Which of the following would be the best option for a music recommender system for/using inhabitants of any environment?: 
Majority ruling, Part diversification or Full diversification? Does this depend on the amount of people in the environment? Does this depend on the type of environment (e.g. restaurant, disco, gym)?

Reference:  McCarthy J., Anagnost T.  (1998). MUSICFX: An Arbiter of Group Preferences for Computer Supported Collaborative Workouts. Conference on Computer Supported Cooperative Work (CSCW ’98).
  
    Edited by Omar Hanafi on 5 Feb at 10:50"
"1581151650-78","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","McCarthy, J. F., & Anagnost, T. D. (1998, November). MusicFX: an arbiter of group preferences for computer supported collaborative workouts. In Proceedings of the 1998 ACM conference on Computer supported cooperative work (pp. 363-372).
 
Discussion topic:
Does this article still have practical relevance? Nowadays, for example, people wear air pods all day, also while shopping and during exercising, etc. That is why a group preference arbition system to influence the selection of music is no longer relevant/necessary.  In what other way could the findings of this paper be used in the future?"
"1581151650-91","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","The music system seems to be an improvement over the previous situation: a vast majority likes the system; they feel heard in their taste and the average satisfaction highly exceeds the average preference. The question remains on how to optimize their new system: is it better to average the score (and thus preference) of the total group of gym-goers, or should the system minimize the number of people that hate the music that is being played? Also, the paper states the one goal is that everyone can have their vote, instead of only the loud minority. It could very well be however that this minority find the music more important than others, and therefore are from a business point of view more important to satisfy than those that are mostly indifferent music-wise for choosing a gym."
"1581151650-76","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","If the people don't update their preferences, would the same music keep playing for the same amount of people everyday? Wouldn't that become redundant?
Reference: McCarthy, J. and Anagnost, T. (1998). MusicFX. Proceedings of the 1998 ACM conference on Computer supported cooperative work - CSCW '98."
"1581151650-64","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","As stated in the paper, the music is played throughout the fitness center including the locker room and the training areas. The visitors of the fitness center move throughout the building (machine to machine, locker room to machine, etc.) during their visit. 
Under the assumption that the music is played through several speakers located throughout the fitness center, the satisfaction of these visitors will improve if the group recommendations is based on the area they are currently situated in."
"1581151650-92","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","The paper discusses the effectiveness of the MusicFX system on playing the preferred music of the inhabitants of the gym.
After MusicFX has been implemented for six weeks they conducted a survey among 71 respondents, which gave positive results on the improvement that had been made.
The research did not conduct a survey before MusicFX was implemented which subsequently gives no zero measurement on how the music was perceived beforehand.
The music accounted for '50%' of the verbal complaints made to staff but there is no indication how many complaints there are in total and from how many of the 600 members they come.
Asking the inhabitants afterwards if they think the music improved could be a hard question because the last time they heard the old music was over six weeks ago and they could simply like the music now instead of thinking it really improved."
"1581151650-67","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","The survey in the paper by McCarthy, J. F., & Anagnost, T. D (1998) was conducted six weeks after the implementations of MusicFX.

Wouldn't it be more accurate to conduct a survey after every visit?
25% of the members considered active were surveyed. Is that enough to make the results statistically significant?"
"1581151650-74","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","Inference requires better study of human factors.
To reach a solid conclusion one would have to conduct more empirical studies that are carefully tailored. The empirical results obtained from gym surveys are vastly influenced social and psychological factors.  Humans are complex and have greatly varying tastes and perceptions, as such the interpretation of satisfaction levels is tricky. Even if a well designed satisfaction scale is explained to people attending an experiment, there remains un-observable factors that manipulate the outcome ( J. Masthoff, 2015, pp 764-766). 
  
    Edited by Alper Bulut on 4 Feb at 22:13"
"1581151650-84","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","The music preference is measured for only fitness, but there could be different kind of fitness and therefore different kind of music preferences.  (With Spinning you will likely prefer a higher tempo, then for example when you are stretching)"
"1581151650-93","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","The paper states that ""The vast majority of fitness center members who are affected by the actions of hlusIcFX are happy with the system, both by their own account and according to a quantitative assessment of what they have been listening to.""
However, they only evaluated the MusicFX system with 1 questionnaire, after 6 weeks. What if less and less people keep using the system and after a few weeks only the most active members regulate the music? Shouldn't they have conducted more questionnaires before concluding that every member is happy with the new system."
"1581151650-94","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","It is hard to generalise someones taste in music through some generic preferences as most people prefer different music in different settings. For example, when going to the gym I prefer other music than while having dinner in an Italian restaurant."
"1581151650-66","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","In the first paper, they discussed the group recommender system on music played in a gym and that the average person experiences three genre changes during their fitness session. However, the authors do not take the order of these genres into account. Which can be a great influence on the “liking” of a song for a person. For instance when a classical song is played right after a Rock or Hardcore song."
"1581151650-89","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","As mentioned in the paper, some shy people do not raise their voice for the music-choice. People come to the fitness center to work out, and their main focus is the workout. The MusicFx automatically plays from the top genre list, and reasonably we can predict or assume that shy people would not mention even if they like or dislike the auto-played music choice, or they may listen to music from their phone. Thus, 71 responses, which is 25% of members, cannot represent the preferences of fitness center people. The experiment of fitness center music preference seems not a good experiment to represent that the intelligent environment can sense and respond effectively to the preferences of its inhabitants."
"1581151650-71","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","Discussion topic
I wonder to what extent this system actually works in practice. I feel like its users are required to have great interest in controlling environmental factors which I think is not always the case. I think many people will rather just go with the music that plays instead of going through the 'hassle' of going to this system prior to their workout. In short, does the effort of going through the system weigh up to its benefits?"
"1581151650-81","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","MusicFX in the form tested in the paper seems like an outdated solution, especially given current technology. Nowadays people prefer creating their own personal Spotify playlist when going for a workout, and “speaker music” (if you will) seems like something of the past. One could argue that solutions similar to musicFX could still prove useful in places such as restaurants, but it would obviously require some sort of modernization.
- Do you believe that a solution such as musicFX still have a place in the current world. If so, do you think it should be updated? What features should be updated?
One application I could see for it would be as a solution for radio stations. If the preferences of the listeners of certain stations at a certain time could somehow be known to an algorithm, which in turn could adapt the musical queue of the radio station accordingly, it could perhaps improve listeners' satisfaction.
- Do you think such an application could prove useful? If not, why? Do you believe it would be achievable with current technology?"
"1581151650-72","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","Discussion point:
 
People submit their preference form when they first join the gym. If people submit their form, but will continue to use their own music (did walkmans already exist in 1998?), then their preference is taken into account whereas they are not listening and not updating their preference. This could effect the outcome of the research. If the walkman didn't exist yet, then still the introduction of peoples own music devices could potentially influence the reproduction of this research if it was reproduced now."
"1581151650-68","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","The system proposed in this paper implies a great user involvement in order to function.  But will the user actually be willing to get involved in the process?
In other words,  the system relies on the active and direct action of its users for two of its main features, that is, recognizing the people present in the fitness center at any given moment (people need to actually log into the system every time), and keeping track of user's preferences (people have to explicitly and manually manage they preferences by providing them in the first place and adjusting them afterward). Will the users always participate actively?"
"1581151650-62","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","The first paper introduces a group recommender system on music played in a fitness center and states that most people on average experience three genre changes under the system during their fitness session. However, the authors ignore the issue of the order of the genres in the sequence, which is suggested as an important aspect of group recommender systems by Masthoff (2015).  For example, I can imagine someone who rates classical music on its own with zero (don't mind about the music), to be more negative in their ratings on classical music when the classical music is played directly after Rock music.
Masthoff, J. (2015). Group recommender systems: aggregation, satisfaction and group attributes. In recommender systems handbook (pp. 743-776). Springer, Boston, MA.
  
    Edited by Myrthe Wouters on 4 Feb at 14:05"
"1581151650-87","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","McCarthy and Anagnost in the paper propose to use various metrics by logging details of its members like their preference of each music genre(Preference Database) taking any value between -2 and +2 and finally using a summation formula for aggregating the preference of the group(Group Preference Arbitration Algorithm). [McCarthy et al Pg. 365]
This aggregation formula magnifies and shifts all the preference values onto a scale starting from 0. However, later in the paper, the authors define a new evaluation metric (Average Satisfaction of FX Members) where the original unshifted preference values are used.[McCarthy et al Pg. 369]
The authors claim to have an overall satisfaction rating of 0.64 for the 6 week period following the systems installation[McCarthy et al Pg.369] comparing it to the satisfaction rating before installation being -0.38. However it would be interesting to see how much of that impact is due to the different scales  being used in collection and evaluation.
  
    Edited by Sumeet Zankar on 5 Feb at 11:17"
"1581151650-77","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","Something is interesting in the distribution of people’s musical preferences (figure 5): Mccarthy, J. F., & Anagnost, T. D. (1998). MusicFX. Proceedings of the 1998 ACM Conference on Computer Supported Cooperative Work - CSCW 98.  And is the changes in the preferences by the users, and leads to asking how drastically they can change their preferences towards negative."
"1581151650-88","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","- Normalization could be used for the user rating, so that it refers to the overall rating of the user.
- In contrast to the quadratic average without Misery approach, other methods to calculate the group score could be used as multiplicative strategy for example.
- The effect of the actual genre is not taken into account for the next genre played, so that even an approved genre like Hottest Hits played after Hottest Country could lead to a bigger disapproaval because of the change in tone and rythm."
"1581151650-80","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","Discussion topic:
The researchers conducted a survey after six weeks to find out if people thought the music had improved, stayed the same, or got worse. Is this a good approach? Another approach could be to have to have a group that is unaware the system has been implemented and one control group and measure the general satisfaction with the music. In this way, there is less chance of bias (e.g. Hawthorne-effect).
  
    Edited by Jarno Smit on 4 Feb at 21:42"
"1581151650-61","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","The paper states that it evaluated the results with (1) a poll and (2) looking into the data. My discussion point is based on (1) the poll. 
 
They only evaluated the results of the poll afterwards with 1 questionnaire. Would the results of (1) the poll be better if they implemented a zero measurement (nulmeting) before implementing the system and comparing that with a second questionnaire being done after implementing the system?
 
I can imagine finding it hard to fill in a questionnaire and trying to think back about how something in the past and comparing it with the present."
"1581151650-65","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","Discussion topic:  
MusicFX  chooses which music to play based on the amount of votes  of the people who are at that moment in time in the  fitness center. Does this suppose that an intelligent environment will always respond effectively to the preferences of its inhabitants if it makes choices based on the amount of votes?
(In this case, when it chooses for the option which has the most votes.)"
"1581151650-63","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","Evaluation metrics used: Is the poll an effective method to evaluate the acceptance of the inhabitants after using MusicFX, is the percentage of people participated in the poll representative, are the answers given biased to other factors, is the definition of the active users useful  enough to draw results?"
"1581151650-69","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","MUSICFX, a group preference arbitration system offers a possible solution to maximize the satisfaction level for the selection of the music stations broadcasted in a gym. The paper had shown a positive result of the recommendation system, as it is able to positively influence the preferences of the inhabitants of the gym environment. However, this article does not clarify some aspects that may negatively affect the outcome of the algorithm. The project has been conducted on a given number of inhabitants and a fixed number of genres. This makes it easier that almost every inhabitant provides a preference for every genre. If the algorithm does not have data available for some genres, it may encounter a rating problem. If it is true that the study demonstrates that there is a significant increment in the positive reactions of the inhabitants to the music recommendation system, will this system increase the rating efficacy in the long term? Is the algorithm suitable for a wide genre selection?
  
    Edited by Davide Carnevale on 4 Feb at 17:22"
"1581151650-85","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","In the paper it says they are using the preferences of current inhabitants to recommend the music, but gym is a place where everyday new people join and what if the new member don't have the same music preference or related music preference.
  
    Edited by Irfan Ahmed on 5 Feb at 10:42"
"1581151650-83","https://tilburguniversity.instructure.com/courses/3076/discussion_topics/33715","The music preference is measured for only fitness, but there could be different kind of fitness and therefore different kind of music preferences.  (With Spinning you will likely prefer a higher tempo, then for example when you are stretching)"
